#!/usr/bin/env python3
"""
Create Sample Data for Local Testing
====================================

This script creates a small sample dataset for local testing.
"""

import os
import json
from pathlib import Path

def create_sample_amr_data():
    """Create sample AMR data for testing."""
    
    # Sample Vietnamese sentences with their AMR representations
    sample_data = [
        {
            "sentence": "T√¥i y√™u Vi·ªát Nam",
            "amr": "(y / y√™u\n    :ARG0 (t / t√¥i)\n    :ARG1 (v / Vi·ªát_Nam))"
        },
        {
            "sentence": "C√¥ ·∫•y ƒëang h·ªçc ti·∫øng Anh",
            "amr": "(h / h·ªçc\n    :ARG0 (c / c√¥_·∫•y)\n    :ARG1 (t / ti·∫øng_Anh)\n    :aspect (p / progressive))"
        },
        {
            "sentence": "H√¥m nay tr·ªùi ƒë·∫πp",
            "amr": "(ƒë / ƒë·∫πp\n    :ARG1 (t / tr·ªùi)\n    :time (h / h√¥m_nay))"
        },
        {
            "sentence": "Anh ·∫•y ƒëi l√†m b·∫±ng xe bu√Ωt",
            "amr": "(ƒë / ƒëi\n    :ARG0 (a / anh_·∫•y)\n    :ARG4 (l / l√†m)\n    :instrument (x / xe_bu√Ωt))"
        },
        {
            "sentence": "Ch√∫ng t√¥i ƒÉn c∆°m t·ªëi ·ªü nh√† h√†ng",
            "amr": "(ƒÉ / ƒÉn\n    :ARG0 (c / ch√∫ng_t√¥i)\n    :ARG1 (c2 / c∆°m_t·ªëi)\n    :location (n / nh√†_h√†ng))"
        },
        {
            "sentence": "Em b√© ƒëang ng·ªß trong ph√≤ng",
            "amr": "(n / ng·ªß\n    :ARG0 (e / em_b√©)\n    :location (p / ph√≤ng)\n    :aspect (p2 / progressive))"
        },
        {
            "sentence": "B·ªë m·∫π t√¥i s·ªëng ·ªü H√† N·ªôi",
            "amr": "(s / s·ªëng\n    :ARG0 (b / b·ªë_m·∫π\n        :poss (t / t√¥i))\n    :location (h / H√†_N·ªôi))"
        },
        {
            "sentence": "Sinh vi√™n ƒë·ªçc s√°ch trong th∆∞ vi·ªán",
            "amr": "(ƒë / ƒë·ªçc\n    :ARG0 (s / sinh_vi√™n)\n    :ARG1 (s2 / s√°ch)\n    :location (t / th∆∞_vi·ªán))"
        },
        {
            "sentence": "C·∫≠u b√© ch∆°i b√≥ng ƒë√° v·ªõi b·∫°n",
            "amr": "(c / ch∆°i\n    :ARG0 (c2 / c·∫≠u_b√©)\n    :ARG1 (b / b√≥ng_ƒë√°)\n    :accompanier (b2 / b·∫°n))"
        },
        {
            "sentence": "C√¥ gi√°o d·∫°y to√°n cho h·ªçc sinh",
            "amr": "(d / d·∫°y\n    :ARG0 (c / c√¥_gi√°o)\n    :ARG1 (t / to√°n)\n    :ARG2 (h / h·ªçc_sinh))"
        },
        {
            "sentence": "√îng ·∫•y mua xe m·ªõi h√¥m qua",
            "amr": "(m / mua\n    :ARG0 (√¥ / √¥ng_·∫•y)\n    :ARG1 (x / xe\n        :mod (m2 / m·ªõi))\n    :time (h / h√¥m_qua))"
        },
        {
            "sentence": "Ch√∫ng ta c·∫ßn b·∫£o v·ªá m√¥i tr∆∞·ªùng",
            "amr": "(c / c·∫ßn\n    :ARG0 (c2 / ch√∫ng_ta)\n    :ARG1 (b / b·∫£o_v·ªá\n        :ARG1 (m / m√¥i_tr∆∞·ªùng)))"
        },
        {
            "sentence": "C√¥ ·∫•y n·∫•u ƒÉn r·∫•t ngon",
            "amr": "(n / n·∫•u_ƒÉn\n    :ARG0 (c / c√¥_·∫•y)\n    :manner (n2 / ngon\n        :degree (r / r·∫•t)))"
        },
        {
            "sentence": "Anh trai t√¥i l√†m b√°c sƒ©",
            "amr": "(l / l√†m\n    :ARG0 (a / anh_trai\n        :poss (t / t√¥i))\n    :ARG1 (b / b√°c_sƒ©))"
        },
        {
            "sentence": "Tr·∫ª em th√≠ch xem phim ho·∫°t h√¨nh",
            "amr": "(t / th√≠ch\n    :ARG0 (t2 / tr·∫ª_em)\n    :ARG1 (x / xem\n        :ARG1 (p / phim_ho·∫°t_h√¨nh)))"
        },
        {
            "sentence": "B√† ngo·∫°i k·ªÉ chuy·ªán cho ch√°u",
            "amr": "(k / k·ªÉ\n    :ARG0 (b / b√†_ngo·∫°i)\n    :ARG1 (c / chuy·ªán)\n    :ARG2 (c2 / ch√°u))"
        },
        {
            "sentence": "Ch√∫ng t√¥i ƒëi du l·ªãch m√πa h√®",
            "amr": "(ƒë / ƒëi_du_l·ªãch\n    :ARG0 (c / ch√∫ng_t√¥i)\n    :time (m / m√πa_h√®))"
        },
        {
            "sentence": "C·∫≠u ·∫•y ch·∫°y r·∫•t nhanh",
            "amr": "(c / ch·∫°y\n    :ARG0 (c2 / c·∫≠u_·∫•y)\n    :manner (n / nhanh\n        :degree (r / r·∫•t)))"
        },
        {
            "sentence": "M·∫π t√¥i tr·ªìng hoa trong v∆∞·ªùn",
            "amr": "(t / tr·ªìng\n    :ARG0 (m / m·∫π\n        :poss (t2 / t√¥i))\n    :ARG1 (h / hoa)\n    :location (v / v∆∞·ªùn))"
        },
        {
            "sentence": "H·ªçc sinh l√†m b√†i t·∫≠p v·ªÅ nh√†",
            "amr": "(l / l√†m\n    :ARG0 (h / h·ªçc_sinh)\n    :ARG1 (b / b√†i_t·∫≠p_v·ªÅ_nh√†))"
        }
    ]
    
    return sample_data

def create_amr_file(data, output_file):
    """Create AMR file in the expected format."""
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for i, item in enumerate(data):
            # Write sentence
            f.write(f"#::snt {item['sentence']}\n")
            # Write AMR
            f.write(f"{item['amr']}\n")
            
            # Add separator except for last item
            if i < len(data) - 1:
                f.write("\n")

def create_jsonl_file(data, output_file):
    """Create JSONL file for direct training."""
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for item in data:
            json_item = {
                "input": item['sentence'],
                "output": item['amr']
            }
            json.dump(json_item, f, ensure_ascii=False)
            f.write('\n')

def main():
    """Create sample data files."""
    
    print("üîÑ Creating sample data for local testing...")
    
    # Create directories
    data_dir = Path("data")
    train_dir = data_dir / "train"
    processed_dir = data_dir / "processed_local"
    
    train_dir.mkdir(parents=True, exist_ok=True)
    processed_dir.mkdir(parents=True, exist_ok=True)
    
    # Get sample data
    sample_data = create_sample_amr_data()
    
    # Split data
    total_samples = len(sample_data)
    train_size = int(total_samples * 0.7)  # 70% for training
    val_size = int(total_samples * 0.2)    # 20% for validation
    
    train_data = sample_data[:train_size]
    val_data = sample_data[train_size:train_size + val_size]
    test_data = sample_data[train_size + val_size:]
    
    print(f"üìä Data split:")
    print(f"  Train: {len(train_data)} samples")
    print(f"  Validation: {len(val_data)} samples")
    print(f"  Test: {len(test_data)} samples")
    
    # Create AMR file for processing demo
    amr_file = train_dir / "sample_amr.txt"
    create_amr_file(sample_data, amr_file)
    print(f"‚úÖ Created AMR file: {amr_file}")
    
    # Create JSONL files for direct training
    train_file = processed_dir / "train.jsonl"
    val_file = processed_dir / "val.jsonl"
    test_file = processed_dir / "test.jsonl"
    
    create_jsonl_file(train_data, train_file)
    create_jsonl_file(val_data, val_file)
    create_jsonl_file(test_data, test_file)
    
    print(f"‚úÖ Created training files:")
    print(f"  {train_file}")
    print(f"  {val_file}")
    print(f"  {test_file}")
    
    # Create a combined file for processing demo
    all_file = processed_dir / "amr_training_data.jsonl"
    create_jsonl_file(sample_data, all_file)
    print(f"‚úÖ Created combined file: {all_file}")
    
    print("\nüéØ Next steps:")
    print("1. Test data processing:")
    print("   python main.py process-data --input-dir data/train --output-dir data/processed_local")
    print("\n2. Test training:")
    print("   python main.py train --config config/local_test_config.yaml")
    print("\n3. Test evaluation:")
    print("   python main.py evaluate --model-path models/amr_model_local --test-data data/processed_local/test.jsonl")
    print("\n4. Test prediction:")
    print("   python main.py predict --model-path models/amr_model_local --text 'T√¥i y√™u Vi·ªát Nam' --format")

if __name__ == "__main__":
    main()
